{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of instances:  68\n",
      "Num of care instances:  27\n",
      "Point num before sampling:  81369\n",
      "Point num after sampling:  50000\n",
      "same\n",
      "choices:  [26870 70335 78721 ... 17759  5257 20278]\n",
      "choices1:  [79857 64628 22615 ... 12162 17664  7198]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import numpy as np\n",
    "BASE_DIR = \"D:/aaaaaaaaaaaaaaaaa/23-24/astar/1-2data/SDCoT-main/SDCoT-main/cfg\"\n",
    "sys.path.append(BASE_DIR)\n",
    "sys.path.append(os.path.join(BASE_DIR, '../cfg/'))\n",
    "from scannet_cfg import cfg\n",
    "from load_scannet_data import export\n",
    "\n",
    "SCANNET_DIR = 'scans'\n",
    "LABEL_MAP_FILE = 'meta_data/scannetv2-labels.combined.tsv'\n",
    "\n",
    "def export_one_scan(scan_name, output_filename_prefix):    \n",
    "    mesh_file = os.path.join(SCANNET_DIR, scan_name, scan_name + '_vh_clean_2.ply')\n",
    "    agg_file = os.path.join(SCANNET_DIR, scan_name, scan_name + '.aggregation.json')\n",
    "    seg_file = os.path.join(SCANNET_DIR, scan_name, scan_name + '_vh_clean_2.0.010000.segs.json')\n",
    "    meta_file = os.path.join(SCANNET_DIR, scan_name, scan_name + '.txt') # includes axisAlignment info for the train set scans.   \n",
    "    mesh_vertices, semantic_labels, instance_labels, instance_bboxes, instance2semantic = \\\n",
    "        export(mesh_file, agg_file, seg_file, meta_file, LABEL_MAP_FILE, None)\n",
    "\n",
    "    mask = np.logical_not(np.in1d(semantic_labels, cfg.DONOTCARE_CLASS_IDS))\n",
    "    mesh_vertices = mesh_vertices[mask,:]\n",
    "    semantic_labels = semantic_labels[mask]\n",
    "    instance_labels = instance_labels[mask]\n",
    "\n",
    "    num_instances = len(np.unique(instance_labels))\n",
    "    print('Num of instances: ', num_instances)\n",
    "\n",
    "    bbox_mask = np.in1d(instance_bboxes[:,-1], cfg.NYU40IDS)\n",
    "    instance_bboxes = instance_bboxes[bbox_mask,:]\n",
    "    print('Num of care instances: ', instance_bboxes.shape[0])\n",
    "\n",
    "    if instance_bboxes.shape[0] > 0:\n",
    "        N = mesh_vertices.shape[0]\n",
    "        print('Point num before sampling: ', N)\n",
    "        if N > cfg.MAX_NUM_POINT:\n",
    "            print('Point num after sampling: ', cfg.MAX_NUM_POINT)\n",
    "            choices = np.random.choice(N, cfg.MAX_NUM_POINT, replace=False)\n",
    "            choices1= np.random.choice(N, cfg.MAX_NUM_POINT, replace=False)\n",
    "            if choices.all()==choices1.all():\n",
    "                print('same')\n",
    "            else:\n",
    "                print('not same')\n",
    "            print('choices: ', choices)\n",
    "            print('choices1: ', choices1)\n",
    "            mesh_vertices = mesh_vertices[choices, :]\n",
    "            semantic_labels = semantic_labels[choices]\n",
    "            instance_labels = instance_labels[choices]\n",
    "\n",
    "        np.save(output_filename_prefix+'_vert.npy', mesh_vertices)\n",
    "        np.save(output_filename_prefix+'_sem_label.npy', semantic_labels)\n",
    "        np.save(output_filename_prefix+'_ins_label.npy', instance_labels)\n",
    "        np.save(output_filename_prefix+'_bbox.npy', instance_bboxes)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    export_one_scan('scene0000_00', 'scene0000_00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of instances:  68\n",
      "Num of care instances:  27\n",
      "Point num before sampling:  81369\n",
      "Point num after sampling:  50000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import numpy as np\n",
    "BASE_DIR = \"D:/aaaaaaaaaaaaaaaaa/23-24/astar/1-2data/SDCoT-main/SDCoT-main/cfg\"\n",
    "sys.path.append(BASE_DIR)\n",
    "sys.path.append(os.path.join(BASE_DIR, '../cfg/'))\n",
    "from scannet_cfg import cfg\n",
    "from load_scannet_data import export\n",
    "\n",
    "SCANNET_DIR = 'scans'\n",
    "LABEL_MAP_FILE = 'meta_data/scannetv2-labels.combined.tsv'\n",
    "\n",
    "def export_one_scan(scan_name, output_filename_prefix):    \n",
    "    mesh_file = os.path.join(SCANNET_DIR, scan_name, scan_name + '_vh_clean_2.ply')\n",
    "    agg_file = os.path.join(SCANNET_DIR, scan_name, scan_name + '.aggregation.json')\n",
    "    seg_file = os.path.join(SCANNET_DIR, scan_name, scan_name + '_vh_clean_2.0.010000.segs.json')\n",
    "    meta_file = os.path.join(SCANNET_DIR, scan_name, scan_name + '.txt') # includes axisAlignment info for the train set scans.   \n",
    "    mesh_vertices, semantic_labels, instance_labels, instance_bboxes, instance2semantic = \\\n",
    "        export(mesh_file, agg_file, seg_file, meta_file, LABEL_MAP_FILE, None)\n",
    "\n",
    "    mask = np.logical_not(np.in1d(semantic_labels, cfg.DONOTCARE_CLASS_IDS))\n",
    "    mesh_vertices = mesh_vertices[mask,:]\n",
    "    semantic_labels = semantic_labels[mask]\n",
    "    instance_labels = instance_labels[mask]\n",
    "\n",
    "    num_instances = len(np.unique(instance_labels))\n",
    "    print('Num of instances: ', num_instances)\n",
    "\n",
    "    bbox_mask = np.in1d(instance_bboxes[:,-1], cfg.NYU40IDS)\n",
    "    instance_bboxes = instance_bboxes[bbox_mask,:]\n",
    "    print('Num of care instances: ', instance_bboxes.shape[0])\n",
    "\n",
    "    if instance_bboxes.shape[0] > 0:\n",
    "        N = mesh_vertices.shape[0]\n",
    "        print('Point num before sampling: ', N)\n",
    "        if N > cfg.MAX_NUM_POINT:\n",
    "            print('Point num after sampling: ', cfg.MAX_NUM_POINT)\n",
    "            choices = np.random.choice(N, cfg.MAX_NUM_POINT, replace=False)\n",
    "\n",
    "            mesh_vertices = mesh_vertices[choices, :]\n",
    "            semantic_labels = semantic_labels[choices]\n",
    "            instance_labels = instance_labels[choices]\n",
    "\n",
    "        np.save(output_filename_prefix+'_vert.npy', mesh_vertices)\n",
    "        np.save(output_filename_prefix+'_sem_label.npy', semantic_labels)\n",
    "        np.save(output_filename_prefix+'_ins_label.npy', instance_labels)\n",
    "        np.save(output_filename_prefix+'_bbox.npy', instance_bboxes)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    export_one_scan('scene0000_00', 'scene0000_00')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
